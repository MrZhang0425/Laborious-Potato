# 说明

* **爬取免费代理网站：**[快代理](https://www.kuaidaili.com/free/)
* **爬虫框架及所用工具包简介**
	* scrapy:用crawlspider从快代理网址中爬取所有的免费代理ip，存储于csv文件中，时间问题只爬取了一部分页面
	
	* requests：用于验证代理IP是否可用，通过设置代理ip后对www.baidu.com发送请求，若返回的statu_codes为200,则为可用,并存入redis中
	
	* 进程池：由于数据太多，requests验证过慢，使用进程池的方式来验证
	
	* 在crawlspider中，在pipelines.py中将爬取的ip按行存入csv文件，在middlewares.py中随机选择UserAgent
	
	
	